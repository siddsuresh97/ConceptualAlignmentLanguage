{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# base_dir = os.path.abspath('/mnt/ws/home/xyu/ConceptualAlignmentLanguage/tripletNCE')\n",
    "base_dir = os.path.abspath('/mnt/dv/wid/projects3/Rogers-nsf-ind-diff/sid/Projects/ConceptualAlignmentLanguage/tripletNCE')\n",
    "save_dir = os.path.join(base_dir,'results')\n",
    "data_dir = os.path.join(base_dir,'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# torch.manual_seed(0)\n",
    "import wandb\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "from torch.utils.data import TensorDataset,Dataset, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# from neurora.rdm_corr import rdm_correlation_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLabelModel(nn.Module):\n",
    "    def __init__(self, encoded_space_dim=64, num_classes=10):\n",
    "        super().__init__()\n",
    "        \"\"\n",
    "        ### Convolutional section\n",
    "       ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "    \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        ### Linear section\n",
    "        ## changed 32*4*4 to 32*2*2\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(32*2*2, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, encoded_space_dim)\n",
    "        )\n",
    "\n",
    "        ## triplet projection module\n",
    "        self.decoder_triplet_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, 32),\n",
    "            nn.ReLU(True)\n",
    "         \n",
    "        )\n",
    "        ##labeling module\n",
    "        self.decoder_labels_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16, num_classes),\n",
    "        )\n",
    "\n",
    "        ### initialize weights using xavier initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        batch_s = x.size(0)\n",
    "        img_features = self.encoder_cnn(x)\n",
    "        img_features = self.flatten(img_features)\n",
    "        \n",
    "        enc_latent = self.encoder_lin(img_features)\n",
    "\n",
    "        triplet_latent = self.decoder_triplet_lin(enc_latent)\n",
    "        label = self.decoder_labels_lin(enc_latent)\n",
    "        # label = F.softmax(label,dim=1)\n",
    "        return enc_latent, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### custom loss computing triplet loss and labeling loss\n",
    "\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, margin=10):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, anchor, positive, negative, label, pred_label):\n",
    "        cosine_sim = torch.nn.CosineSimilarity(1)\n",
    "        # distance_positive = torch.tensor(1)-cosine_sim(anchor,positive)\n",
    "   \n",
    "        # distance_negative = torch.tensor(1)-cosine_sim(anchor,negative)\n",
    "\n",
    "        # triplet_loss = torch.maximum(distance_positive - distance_negative + self.margin, torch.tensor(0))\n",
    "        # triplet_loss = torch.sum(triplet_loss)\n",
    "        triplet_loss = (nn.TripletMarginWithDistanceLoss( distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)))\n",
    "        triplet_loss = triplet_loss(anchor, positive, negative)\n",
    "        label_loss = self.cross_entropy(pred_label.float().softmax(dim = 1), label.float())\n",
    "        total_loss = triplet_loss + label_loss\n",
    "        return triplet_loss, label_loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = TripletLabelModel()\n",
    "# cifar_model_path = '../../data/CIFAR10_NCE_i_1e-05_50.pth'\n",
    "# t.load_state_dict(torch.load(cifar_model_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TrainModels(nn.Module):\n",
    "    def __init__(self, latent_dims, num_classes, weights_path=None):\n",
    "        super(TrainModels, self).__init__()\n",
    "        self.triplet_lab_model = TripletLabelModel(latent_dims, 10) ### load cifar model\n",
    "        if weights_path!=None:\n",
    "            cifar_model_path = '/mnt/dv/wid/projects3/Rogers-nsf-ind-diff/sid/Projects/ConceptualAlignmentLanguage/tripletNCE/data/CIFAR10_NCE_i_1e-05_50.pth'\n",
    "            self.triplet_lab_model.load_state_dict(torch.load(cifar_model_path))\n",
    "            self.triplet_lab_model.decoder_labels_lin[4] = nn.Linear(16, num_classes)\n",
    "        self.custom_loss = CustomLoss()\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, anchor_im, positive_im, negative_im):\n",
    "        anchor_latent, anchor_label = self.triplet_lab_model(anchor_im)\n",
    "        positive_latent, _ = self.triplet_lab_model(positive_im)\n",
    "        negative_latent, _ = self.triplet_lab_model(negative_im)\n",
    "\n",
    "        return anchor_latent, positive_latent, negative_latent, anchor_label\n",
    "\n",
    "    def test_epoch(self, test_data):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "        self.eval()\n",
    "        with torch.no_grad(): # No need to track the gradients\n",
    "            # Define the lists to store the outputs for each batch\n",
    "            test_triplet_loss = []\n",
    "            test_label_loss = []\n",
    "            test_total_loss = []\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for anchor_ims, contrast_ims, labels in test_data:\n",
    "                # Move tensor to the proper device\n",
    "                anchor_ims = anchor_ims.to(device)\n",
    "                contrast_ims = contrast_ims.to(device)\n",
    "                labels = F.one_hot(labels, num_classes=self.num_classes)\n",
    "                labels = labels.to(device)\n",
    "                anchor_latent, positive_latent, negative_latent, pred_label = self.forward(anchor_ims, anchor_ims,contrast_ims) \n",
    "                # Append the network output and the original image to the lists\n",
    "                triplet_loss, label_loss, total_loss = self.custom_loss(anchor_latent,\n",
    "                                                                positive_latent, \n",
    "                                                                negative_latent, \n",
    "                                                                labels,\n",
    "                                                                pred_label)\n",
    "                total += labels.size(0)\n",
    "                correct += (torch.argmax(pred_label, dim = 1) == torch.argmax(labels, dim = 1)).sum().item()\n",
    "                test_triplet_loss.append(triplet_loss.item())\n",
    "                test_label_loss.append(label_loss.item())\n",
    "                test_total_loss.append(total_loss.item())\n",
    "        test_triplet_loss = sum(test_triplet_loss)/len(test_triplet_loss)\n",
    "        test_label_loss = sum(test_label_loss)/len(test_label_loss)\n",
    "        test_total_loss = sum(test_total_loss)/len(test_total_loss)\n",
    "        test_accuracy = correct/total\n",
    "        return test_triplet_loss, test_label_loss, test_total_loss, test_accuracy\n",
    "\n",
    "    def test_epoch_calculate_representation_separation(self, test_data):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "        self.eval()\n",
    "        with torch.no_grad(): # No need to track the gradients\n",
    "            accuracies = []\n",
    "            for anchor_ims, contrast_ims, labels in test_data:\n",
    "                # Move tensor to the proper device\n",
    "                anchor_ims = anchor_ims.to(device)\n",
    "                contrast_ims = contrast_ims.to(device)\n",
    "                # labels = F.one_hot(labels, num_classes=self.num_classes)\n",
    "                # labels = labels.to(device)\n",
    "                anchor_latent, _, _, _ = self.forward(anchor_ims, anchor_ims,contrast_ims) \n",
    "                # use sklearn to predict labels from anchor_latent\n",
    "                # calculate accuracy\n",
    "                # x's are anchor_latent and y's are labels\n",
    "                # append accuracy to list\n",
    "                # put anchor_latent and labels on cpu and convert to numpy\n",
    "\n",
    "          \n",
    "                anchor_latent = anchor_latent.cpu().numpy()\n",
    "                ### standard scale the data in anchor_latent before fitting to the model\n",
    "                anchor_latent = StandardScaler().fit_transform(anchor_latent)\n",
    "                labels = labels.cpu().numpy()\n",
    "                \n",
    "                lm = linear_model.LogisticRegression()\n",
    "                lm.fit(anchor_latent, labels)\n",
    "                # convert labels to sklearn format\n",
    "                accuracies.append(lm.score(anchor_latent, labels))\n",
    "        accuracy = sum(accuracies)/len(accuracies)\n",
    "        return accuracy\n",
    "\n",
    "    def train_epoch(self, train_data, optimizer, train_mode):\n",
    "        self.train()\n",
    "        train_triplet_loss = []\n",
    "        train_label_loss = []\n",
    "        train_total_loss = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for anchor_ims, contrast_ims, labels in train_data:\n",
    "            \n",
    "            anchor_ims = anchor_ims.to(device)\n",
    "            contrast_ims = contrast_ims.to(device)\n",
    "            labels = F.one_hot(labels, num_classes=self.num_classes)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            anchor_latent, positive_latent, negative_latent, pred_label = self.forward(anchor_ims, anchor_ims,contrast_ims) \n",
    "           \n",
    "           \n",
    "           \n",
    "            triplet_loss, label_loss, total_loss = self.custom_loss(anchor_latent,\n",
    "                                                                positive_latent, \n",
    "                                                                negative_latent, \n",
    "                                                                labels,\n",
    "                                                                pred_label)\n",
    "            \n",
    "            \n",
    "            if train_mode==0:\n",
    "                triplet_loss.backward()\n",
    "            elif train_mode==1:\n",
    "                label_loss.backward()\n",
    "            elif train_mode==2:\n",
    "                total_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            train_triplet_loss.append(triplet_loss.item())\n",
    "            train_label_loss.append(label_loss.item())\n",
    "            train_total_loss.append(total_loss.item())\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.argmax(pred_label, dim = 1) == torch.argmax(labels, dim = 1)).sum().item()\n",
    "        train_triplet_loss = sum(train_triplet_loss)/len(train_triplet_loss)\n",
    "        train_label_loss = sum(train_label_loss)/len(train_label_loss)\n",
    "        train_total_loss = sum(train_total_loss)/len(train_total_loss)\n",
    "        train_accuracy = correct/total\n",
    "        return train_triplet_loss, train_label_loss, train_total_loss, train_accuracy\n",
    "\n",
    "    def training_loop(self, train_data, test_data,train_mode,\n",
    "                      epochs, optimizer):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_triplet_losses = []\n",
    "        val_triplet_losses = []\n",
    "        train_label_losses = []\n",
    "        val_label_losses = []\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        latent_separation_accuracy = 0\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "          train_triplet_loss, train_label_loss, train_total_loss, train_accuracy =self.train_epoch(train_data, optimizer, \n",
    "                                             train_mode)\n",
    "          test_triplet_loss, test_label_loss, test_total_loss, test_accuracy = self.test_epoch(test_data)\n",
    "          separation_accuracy = self.test_epoch_calculate_representation_separation(test_data)\n",
    "          train_losses.append(train_total_loss)\n",
    "          val_losses.append(test_total_loss)\n",
    "          train_triplet_losses.append(train_triplet_loss)\n",
    "          val_triplet_losses.append(test_triplet_loss)\n",
    "          train_label_losses.append(train_label_loss)\n",
    "          val_label_losses.append(test_label_loss)\n",
    "          train_accuracies.append(train_accuracy)\n",
    "          val_accuracies.append(test_accuracy)\n",
    "          wandb.log({\"train triplet loss\": train_triplet_loss, \n",
    "            \"train label loss\":train_label_loss, \n",
    "            \"validation triplet loss\":test_triplet_loss, \n",
    "            \"validation label loss\":test_label_loss, \n",
    "            \"total train loss\":train_total_loss, \n",
    "            \"total validation loss\":test_total_loss, \n",
    "            \"train label accuracy\":train_accuracy, \n",
    "            \"validation label accuracy\":test_accuracy,\n",
    "            'latent separation accuracy':separation_accuracy})\n",
    "        return train_triplet_losses, train_label_losses, val_triplet_losses, val_label_losses ,train_losses, val_losses, train_accuracies, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_A_ims = np.load(os.path.join(data_dir, 'set_A.npy'))\n",
    "set_B_ims = np.load(os.path.join(data_dir, 'set_B.npy'))\n",
    "set_C_ims = np.load(os.path.join(data_dir, 'set_C.npy'))\n",
    "set_A_labs = np.load(os.path.join(data_dir, 'set_A_labs.npy'))\n",
    "set_B_labs = np.load(os.path.join(data_dir, 'set_B_labs.npy'))\n",
    "set_C_labs = np.load(os.path.join(data_dir, 'set_C_labs.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "set_A_sub_ims =[]\n",
    "set_B_sub_ims =[]\n",
    "\n",
    "set_C_sub_ims =[]\n",
    "\n",
    "set_A_sub_labs =[]\n",
    "set_B_sub_labs =[]\n",
    "set_C_sub_labs =[]\n",
    "\n",
    "\n",
    "for i in range (4):\n",
    "    sub_main = set_A_ims[i*600:(i*600)+600]\n",
    "    labels_main = set_A_labs[i*600:(i*600)+600]\n",
    "    np.random.seed(711)\n",
    "    np.random.shuffle(sub_main)\n",
    "    np.random.seed(711)\n",
    "    np.random.shuffle(labels_main)\n",
    "\n",
    "    set_A_sub_ims.append(sub_main[:30])\n",
    "    set_B_sub_ims.append(sub_main[:15])\n",
    "    set_B_sub_ims.append(sub_main[30:45])\n",
    "    set_C_sub_ims.append(sub_main[35:65])\n",
    "\n",
    "    set_A_sub_labs.append(labels_main[:30])\n",
    "    set_B_sub_labs.append(labels_main[:15])\n",
    "    set_B_sub_labs.append(labels_main[30:45])\n",
    "    set_C_sub_labs.append(labels_main[35:65])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##flatten set_A_sub_ims into an array of shape 120,64,64,3\n",
    "set_A_sub_ims = np.concatenate(set_A_sub_ims)\n",
    "set_B_sub_ims = np.concatenate(set_B_sub_ims)\n",
    "set_C_sub_ims = np.concatenate(set_C_sub_ims)\n",
    "\n",
    "set_A_sub_labs = np.concatenate(set_A_sub_labs)\n",
    "set_B_sub_labs = np.concatenate(set_B_sub_labs)\n",
    "set_C_sub_labs = np.concatenate(set_C_sub_labs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A-B: 50% \\\n",
    "A-C: 0% \\\n",
    "B-C: 33.33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###initialize weights and bias tracking\n",
    "def wandb_init(epochs, lr, train_mode, batch_size, model_number,data_set):\n",
    "    wandb.init(project=\"ConceptualAlignment\", settings=wandb.Settings(start_method=\"thread\"))\n",
    "    wandb.config = {\n",
    "      \"learning_rate\": lr,\n",
    "      \"epochs\": epochs,\n",
    "      \"batch_size\": batch_size, \n",
    "      # \"label_ratio\":label_ratio, \n",
    "      \"model_number\": model_number,\n",
    "      \"dataset\": data_set,\n",
    "      \"train_mode\":train_mode,\n",
    "    }\n",
    "    train_mode_dict = {0:'triplet', 1:'label', 2:'label_and_triplet'}\n",
    "    wandb.run.name = f'{data_set}_{train_mode_dict[train_mode]}_{model_number}'\n",
    "    wandb.run.save()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main_code(save_dir, num_models, epochs, num_classes, batch_size,\n",
    "             lr, latent_dims):\n",
    "  if os.path.isdir(save_dir):\n",
    "    pass\n",
    "  else:\n",
    "    os.mkdir(save_dir)\n",
    "  random.seed(42)\n",
    "  np.random.seed(42)\n",
    "  torch.manual_seed(42)\n",
    "  \n",
    "  # test_intervals = [(540, 600), (1140, 1200), (1740, 1800), (2340, 2400)]\n",
    "  test_intervals = [(25, 30), (55, 60), (85, 90), (115, 120)]\n",
    "  # initialize an empty list to hold the indices\n",
    "  val_indices = []\n",
    "\n",
    "  # loop through the intervals and append the indices to the list\n",
    "  for start, stop in test_intervals:\n",
    "      val_indices.extend(list(range(start, stop)))\n",
    "\n",
    "  # train_indices = (np.setdiff1d(np.arange(2400),np.array(val_indices)))\n",
    "  train_indices = (np.setdiff1d(np.arange(120),np.array(val_indices)))\n",
    "\n",
    "  # np.random.seed(56)\n",
    "  # contrast_indices  = np.concatenate((np.random.choice(np.arange(start=600, stop=2400), 600, replace=False),\n",
    "  #               np.random.choice(np.concatenate((np.arange(start=0, stop=600), np.arange(start=1200, stop=2400))), 600, replace=False),\n",
    "  #               np.random.choice(np.concatenate((np.arange(start=0, stop=1200), np.arange(start=1800, stop=2400))), 600, replace=False),\n",
    "  #               np.random.choice(np.arange(start=1800, stop=2400), 600, replace=False)))\n",
    "  contrast_indices  = np.concatenate((np.random.choice(np.arange(start=30, stop=120), 30, replace=False),\n",
    "                np.random.choice(np.concatenate((np.arange(start=0, stop=30), np.arange(start=60, stop=120))), 30, replace=False),\n",
    "                np.random.choice(np.concatenate((np.arange(start=0, stop=60), np.arange(start=90, stop=120))), 30, replace=False),\n",
    "                np.random.choice(np.arange(start=0, stop=90), 30, replace=False)))\n",
    "\n",
    "  # for data_set in ['set_A','set_A2','set_B','set_C']:\n",
    "  for data_set in ['set_A']:\n",
    "    for train_mode in tqdm(range(2, 3)):\n",
    "     # torch.manual_seed(0)\n",
    "      for model in range(num_models):\n",
    "        wandb_init(epochs, lr, train_mode, batch_size, model,data_set)\n",
    "        weights_path = f'../../data/cifar_models/m{model}.pth'\n",
    "\n",
    "        if data_set=='set_A':\n",
    "          train_data = TensorDataset(Resize(32)(torch.tensor(set_A_sub_ims.transpose(0,3,1,2)/255).float()), Resize(32)(torch.tensor(set_A_sub_ims[contrast_indices].transpose(0,3,1,2)/255).float()),\\\n",
    "                                     torch.tensor(set_A_sub_labs).to(torch.int64))\n",
    "          # train_data = TensorDataset(Resize(32)(torch.tensor(set_A_ims.transpose(0,3,1,2)/255).float()), Resize(32)(torch.tensor(set_A_ims.transpose(0,3,1,2)/255).float()),\\\n",
    "          #                            torch.tensor(set_A_labs).to(torch.int64))\n",
    "        else:\n",
    "          exit()\n",
    "        train_size = int(0.7 * len(train_data))\n",
    "        val_size = len(train_data) - train_size\n",
    "        \n",
    "        train_data, val_data = random_split(train_data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "       \n",
    "\n",
    "        train_data = torch.utils.data.DataLoader(train_data, \n",
    "                                                batch_size=batch_size,\n",
    "                                              shuffle=True)\n",
    "        val_data = torch.utils.data.DataLoader(val_data, \n",
    "                                                batch_size=batch_size,\n",
    "                                              shuffle=False)\n",
    "        \n",
    "        \n",
    "        # assert(len(test_data.dataset) == test_size)\n",
    "        assert(len(train_data.dataset) == train_size)\n",
    "        assert(len(val_data.dataset) == val_size)\n",
    "\n",
    "        train_obj = TrainModels(latent_dims, num_classes, weights_path).to(device) # GPU\n",
    "        optimizer = torch.optim.Adam(train_obj.parameters(), lr=lr, weight_decay=1e-05)\n",
    "        train_triplet_losses, train_label_losses, \\\n",
    "          val_triplet_losses, val_label_losses, \\\n",
    "            train_losses, val_losses, train_accuracies, val_accuracies= train_obj.training_loop(train_data = train_data,\n",
    "                                                            test_data = val_data,\n",
    "                                                            epochs = epochs,\n",
    "                                                            optimizer = optimizer, \n",
    "                                                            train_mode = train_mode)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        print('validation triplet loss:',val_triplet_losses[-1],'validation total loss:',val_losses[-1],'validation accuracy:',val_accuracies[-1])\n",
    "        # wandb.log({\"train_img_loss\": train_img_loss, \n",
    "        #           \"train_label_loss\":train_label_loss, \n",
    "        #           \"val_img_loss\":val_img_loss, \n",
    "        #           \"val_label_loss\":val_label_loss, \n",
    "        #           \"train_losses\":train_losses, \n",
    "        #           \"val_losses\":val_losses, \n",
    "        #           \"train_accuracy\":train_accuracy, \n",
    "        #           \"val_accuracy\":val_accuracy})\n",
    "        train_mode_dict = {0:'triplet', 1:'label',2:'label_and_triplet' }\n",
    "        torch.save(train_obj.triplet_lab_model.state_dict(), os.path.join(save_dir,'sid_checkpoints', 'before_self_talk_all_set_A',f'{model}_{data_set}_{train_mode_dict[train_mode]}_{round(val_accuracies[-1], 3)}_sid_ce.pth'))\n",
    "  return val_data\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wobbly-haze-61</strong> at: <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/84htnmh8' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/84htnmh8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240125_181204-84htnmh8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/dv/wid/projects3/Rogers-nsf-ind-diff/sid/Projects/ConceptualAlignmentLanguage/tripletNCE/wandb/run-20240125_181311-2dvsjb7y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/2dvsjb7y' target=\"_blank\">genial-shape-62</a></strong> to <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/2dvsjb7y' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/2dvsjb7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation triplet loss: 0.6189886927604675 validation total loss: 2.012028932571411 validation accuracy: 0.08333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2dvsjb7y) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>▁</td></tr><tr><td>total train loss</td><td>▁</td></tr><tr><td>total validation loss</td><td>▁</td></tr><tr><td>train label accuracy</td><td>▁</td></tr><tr><td>train label loss</td><td>▁</td></tr><tr><td>train triplet loss</td><td>▁</td></tr><tr><td>validation label accuracy</td><td>▁</td></tr><tr><td>validation label loss</td><td>▁</td></tr><tr><td>validation triplet loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>1.0</td></tr><tr><td>total train loss</td><td>1.66787</td></tr><tr><td>total validation loss</td><td>2.01203</td></tr><tr><td>train label accuracy</td><td>0.28571</td></tr><tr><td>train label loss</td><td>1.38737</td></tr><tr><td>train triplet loss</td><td>0.2805</td></tr><tr><td>validation label accuracy</td><td>0.08333</td></tr><tr><td>validation label loss</td><td>1.39304</td></tr><tr><td>validation triplet loss</td><td>0.61899</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">genial-shape-62</strong> at: <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/2dvsjb7y' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/2dvsjb7y</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240125_181311-2dvsjb7y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2dvsjb7y). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/dv/wid/projects3/Rogers-nsf-ind-diff/sid/Projects/ConceptualAlignmentLanguage/tripletNCE/wandb/run-20240125_181321-j250abx8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/j250abx8' target=\"_blank\">solar-snowball-63</a></strong> to <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/j250abx8' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/j250abx8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:00<00:00, 10.65it/s]\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.93s/it]/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:2163: UserWarning: Run (2dvsjb7y) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation triplet loss: 0.6196682453155518 validation total loss: 2.009838104248047 validation accuracy: 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:j250abx8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>▁▁</td></tr><tr><td>total train loss</td><td>█▁</td></tr><tr><td>total validation loss</td><td>█▁</td></tr><tr><td>train label accuracy</td><td>▁█</td></tr><tr><td>train label loss</td><td>█▁</td></tr><tr><td>train triplet loss</td><td>█▁</td></tr><tr><td>validation label accuracy</td><td>▁█</td></tr><tr><td>validation label loss</td><td>█▁</td></tr><tr><td>validation triplet loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>1.0</td></tr><tr><td>total train loss</td><td>1.41522</td></tr><tr><td>total validation loss</td><td>2.00984</td></tr><tr><td>train label accuracy</td><td>0.33333</td></tr><tr><td>train label loss</td><td>1.37645</td></tr><tr><td>train triplet loss</td><td>0.03876</td></tr><tr><td>validation label accuracy</td><td>0.16667</td></tr><tr><td>validation label loss</td><td>1.39017</td></tr><tr><td>validation triplet loss</td><td>0.61967</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-snowball-63</strong> at: <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/j250abx8' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/j250abx8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240125_181321-j250abx8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:j250abx8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/dv/wid/projects3/Rogers-nsf-ind-diff/sid/Projects/ConceptualAlignmentLanguage/tripletNCE/wandb/run-20240125_181334-6facy121</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/6facy121' target=\"_blank\">fast-dust-64</a></strong> to <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/6facy121' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/6facy121</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 3/3 [00:00<00:00, 36.26it/s]\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.78s/it]/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:2163: UserWarning: Run (j250abx8) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation triplet loss: 0.606200098991394 validation total loss: 1.9964025020599365 validation accuracy: 0.2777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6facy121) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>▁▁▁</td></tr><tr><td>total train loss</td><td>█▂▁</td></tr><tr><td>total validation loss</td><td>█▇▁</td></tr><tr><td>train label accuracy</td><td>▁▂█</td></tr><tr><td>train label loss</td><td>█▅▁</td></tr><tr><td>train triplet loss</td><td>█▁▁</td></tr><tr><td>validation label accuracy</td><td>▁▄█</td></tr><tr><td>validation label loss</td><td>█▁▁</td></tr><tr><td>validation triplet loss</td><td>██▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>1.0</td></tr><tr><td>total train loss</td><td>1.38504</td></tr><tr><td>total validation loss</td><td>1.9964</td></tr><tr><td>train label accuracy</td><td>0.5119</td></tr><tr><td>train label loss</td><td>1.36139</td></tr><tr><td>train triplet loss</td><td>0.02365</td></tr><tr><td>validation label accuracy</td><td>0.27778</td></tr><tr><td>validation label loss</td><td>1.3902</td></tr><tr><td>validation triplet loss</td><td>0.6062</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-dust-64</strong> at: <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/6facy121' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/6facy121</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240125_181334-6facy121/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6facy121). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/dv/wid/projects3/Rogers-nsf-ind-diff/sid/Projects/ConceptualAlignmentLanguage/tripletNCE/wandb/run-20240125_181347-clg05gqh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/clg05gqh' target=\"_blank\">exalted-dust-65</a></strong> to <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/clg05gqh' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/clg05gqh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 4/4 [00:00<00:00, 38.11it/s]\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.46s/it]/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:2163: UserWarning: Run (6facy121) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation triplet loss: 0.622480571269989 validation total loss: 2.0152742862701416 validation accuracy: 0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:clg05gqh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>▁▁▁▁</td></tr><tr><td>total train loss</td><td>█▂▂▁</td></tr><tr><td>total validation loss</td><td>▇▆▁█</td></tr><tr><td>train label accuracy</td><td>▁▂▆█</td></tr><tr><td>train label loss</td><td>█▆▄▁</td></tr><tr><td>train triplet loss</td><td>█▂▁▁</td></tr><tr><td>validation label accuracy</td><td>▁▄█▅</td></tr><tr><td>validation label loss</td><td>█▁▁▇</td></tr><tr><td>validation triplet loss</td><td>▆▇▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>1.0</td></tr><tr><td>total train loss</td><td>1.34712</td></tr><tr><td>total validation loss</td><td>2.01527</td></tr><tr><td>train label accuracy</td><td>0.60714</td></tr><tr><td>train label loss</td><td>1.33829</td></tr><tr><td>train triplet loss</td><td>0.00883</td></tr><tr><td>validation label accuracy</td><td>0.22222</td></tr><tr><td>validation label loss</td><td>1.39279</td></tr><tr><td>validation triplet loss</td><td>0.62248</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-dust-65</strong> at: <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/clg05gqh' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/clg05gqh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240125_181347-clg05gqh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:clg05gqh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/dv/wid/projects3/Rogers-nsf-ind-diff/sid/Projects/ConceptualAlignmentLanguage/tripletNCE/wandb/run-20240125_181400-jphb22bl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/jphb22bl' target=\"_blank\">easy-galaxy-66</a></strong> to <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/jphb22bl' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/jphb22bl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 5/5 [00:00<00:00, 37.05it/s]\n",
      "100%|██████████| 1/1 [00:26<00:00, 26.79s/it]/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:2163: UserWarning: Run (clg05gqh) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "100%|██████████| 1/1 [00:26<00:00, 26.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation triplet loss: 0.6387975811958313 validation total loss: 2.041337251663208 validation accuracy: 0.2222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:jphb22bl) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>▁▁▁▁▁</td></tr><tr><td>total train loss</td><td>█▃▂▂▁</td></tr><tr><td>total validation loss</td><td>▃▃▁▄█</td></tr><tr><td>train label accuracy</td><td>▁▂▆██</td></tr><tr><td>train label loss</td><td>█▇▆▄▁</td></tr><tr><td>train triplet loss</td><td>█▂▁▁▁</td></tr><tr><td>validation label accuracy</td><td>▁▄█▅▅</td></tr><tr><td>validation label loss</td><td>▃▁▁▂█</td></tr><tr><td>validation triplet loss</td><td>▄▄▁▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>1.0</td></tr><tr><td>total train loss</td><td>1.31469</td></tr><tr><td>total validation loss</td><td>2.04134</td></tr><tr><td>train label accuracy</td><td>0.61905</td></tr><tr><td>train label loss</td><td>1.30744</td></tr><tr><td>train triplet loss</td><td>0.00725</td></tr><tr><td>validation label accuracy</td><td>0.22222</td></tr><tr><td>validation label loss</td><td>1.40254</td></tr><tr><td>validation triplet loss</td><td>0.6388</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">easy-galaxy-66</strong> at: <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/jphb22bl' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/jphb22bl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240125_181400-jphb22bl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:jphb22bl). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/dv/wid/projects3/Rogers-nsf-ind-diff/sid/Projects/ConceptualAlignmentLanguage/tripletNCE/wandb/run-20240125_181427-6i3p0rd0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/6i3p0rd0' target=\"_blank\">wobbly-frost-67</a></strong> to <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/6i3p0rd0' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/6i3p0rd0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [00:00<00:00, 37.52it/s]\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.44s/it]/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:2163: UserWarning: Run (jphb22bl) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation triplet loss: 0.7250034809112549 validation total loss: 2.2734451293945312 validation accuracy: 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6i3p0rd0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total train loss</td><td>█▅▅▄▄▃▃▂▁▁</td></tr><tr><td>total validation loss</td><td>▁▁▁▁▂▄▅▆██</td></tr><tr><td>train label accuracy</td><td>▁▂▅▆▇▇▇▇██</td></tr><tr><td>train label loss</td><td>██▇▇▆▅▄▃▂▁</td></tr><tr><td>train triplet loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr><tr><td>validation label accuracy</td><td>▁▄█▆▆▆▄▄▄▄</td></tr><tr><td>validation label loss</td><td>▁▁▁▁▂▂▄▆██</td></tr><tr><td>validation triplet loss</td><td>▂▂▁▂▃▅▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>1.0</td></tr><tr><td>total train loss</td><td>1.06491</td></tr><tr><td>total validation loss</td><td>2.27345</td></tr><tr><td>train label accuracy</td><td>0.70238</td></tr><tr><td>train label loss</td><td>1.06214</td></tr><tr><td>train triplet loss</td><td>0.00277</td></tr><tr><td>validation label accuracy</td><td>0.16667</td></tr><tr><td>validation label loss</td><td>1.54844</td></tr><tr><td>validation triplet loss</td><td>0.725</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wobbly-frost-67</strong> at: <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/6i3p0rd0' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/6i3p0rd0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240125_181427-6i3p0rd0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6i3p0rd0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/dv/wid/projects3/Rogers-nsf-ind-diff/sid/Projects/ConceptualAlignmentLanguage/tripletNCE/wandb/run-20240125_181440-7d2bbws1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/7d2bbws1' target=\"_blank\">pleasant-bush-68</a></strong> to <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/7d2bbws1' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/7d2bbws1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [00:00<00:00, 36.88it/s]\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.71s/it]/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:2163: UserWarning: Run (6i3p0rd0) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "100%|██████████| 1/1 [00:13<00:00, 13.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation triplet loss: 0.24147076904773712 validation total loss: 1.4086817502975464 validation accuracy: 0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7d2bbws1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total train loss</td><td>█▆▆▅▅▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>total validation loss</td><td>▆▆▆▆▆▇▇▇███▇▇▆▅▄▃▃▂▁</td></tr><tr><td>train label accuracy</td><td>▁▁▃▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>train label loss</td><td>███▇▇▆▆▅▄▄▄▃▃▃▃▂▂▂▁▁</td></tr><tr><td>train triplet loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation label accuracy</td><td>▁▂▄▃▃▃▂▂▂▂▂▂▃▄▄▅▆▆▇█</td></tr><tr><td>validation label loss</td><td>▅▅▅▅▅▆▆▇████▇▆▅▄▃▃▂▁</td></tr><tr><td>validation triplet loss</td><td>▆▆▆▆▇▇▇████▇▆▅▅▄▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>1.0</td></tr><tr><td>total train loss</td><td>0.83984</td></tr><tr><td>total validation loss</td><td>1.40868</td></tr><tr><td>train label accuracy</td><td>0.95238</td></tr><tr><td>train label loss</td><td>0.8367</td></tr><tr><td>train triplet loss</td><td>0.00313</td></tr><tr><td>validation label accuracy</td><td>0.55556</td></tr><tr><td>validation label loss</td><td>1.16721</td></tr><tr><td>validation triplet loss</td><td>0.24147</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pleasant-bush-68</strong> at: <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/7d2bbws1' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/7d2bbws1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240125_181440-7d2bbws1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:7d2bbws1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/dv/wid/projects3/Rogers-nsf-ind-diff/sid/Projects/ConceptualAlignmentLanguage/tripletNCE/wandb/run-20240125_181454-g8h5txl9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/g8h5txl9' target=\"_blank\">lilac-glitter-69</a></strong> to <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/g8h5txl9' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/g8h5txl9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 50/50 [00:01<00:00, 38.74it/s]\n",
      "100%|██████████| 1/1 [00:14<00:00, 14.60s/it]/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:2163: UserWarning: Run (7d2bbws1) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "100%|██████████| 1/1 [00:14<00:00, 14.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation triplet loss: 0.15564759075641632 validation total loss: 1.1976622343063354 validation accuracy: 0.6944444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total train loss</td><td>█▆▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total validation loss</td><td>▆▆▆▆▇▇████▇▆▅▄▄▃▂▁▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train label accuracy</td><td>▁▁▃▄▄▅▅▅▅▅▅▆▆▆▇▇████████████████████████</td></tr><tr><td>train label loss</td><td>███▇▇▆▅▅▄▄▄▄▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train triplet loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation label accuracy</td><td>▁▂▃▂▂▂▂▂▂▂▂▃▅▅▅▅██▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation label loss</td><td>▆▆▆▆▆▇▇████▇▅▄▄▄▂▁▁▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation triplet loss</td><td>▇▇▇▇▇█████▇▆▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>latent separation accuracy</td><td>1.0</td></tr><tr><td>total train loss</td><td>0.74373</td></tr><tr><td>total validation loss</td><td>1.19766</td></tr><tr><td>train label accuracy</td><td>1.0</td></tr><tr><td>train label loss</td><td>0.74373</td></tr><tr><td>train triplet loss</td><td>0.0</td></tr><tr><td>validation label accuracy</td><td>0.69444</td></tr><tr><td>validation label loss</td><td>1.04201</td></tr><tr><td>validation triplet loss</td><td>0.15565</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lilac-glitter-69</strong> at: <a href='https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/g8h5txl9' target=\"_blank\">https://wandb.ai/sid-academic-team/ConceptualAlignment/runs/g8h5txl9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240125_181454-g8h5txl9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "\n",
    "num_classes = 4 # Number of unique class labels in the dataset\n",
    "latent_dims = 64\n",
    "epochs = 1\n",
    "lr = 0.005\n",
    "num_models = 1\n",
    "batch_size = 256\n",
    "save_dir = save_dir\n",
    "# to check if dataset is the same\n",
    "val_datas = []\n",
    "for epochs in [1, 2, 3, 4, 5, 10, 20, 50]:\n",
    "    val_datas.extend([main_code(save_dir, num_models, epochs, num_classes, batch_size,\n",
    "                lr, latent_dims)])\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want the final layer logits , compute error based on the maximum logits ground truth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sid changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "contrast_indices  = np.concatenate((np.random.choice(np.arange(start=30, stop=120), 30, replace=False),\n",
    "                np.random.choice(np.concatenate((np.arange(start=0, stop=30), np.arange(start=60, stop=120))), 30, replace=False),\n",
    "                np.random.choice(np.concatenate((np.arange(start=0, stop=60), np.arange(start=90, stop=120))), 30, replace=False),\n",
    "                np.random.choice(np.arange(start=0, stop=90), 30, replace=False)))\n",
    "# train_data = TensorDataset(Resize(32)(torch.tensor(set_A_sub_ims.transpose(0,3,1,2)/255).float()), Resize(32)(torch.tensor(set_A_sub_ims[contrast_indices].transpose(0,3,1,2)/255).float()),\\\n",
    "#                                      torch.tensor(set_A_sub_labs).to(torch.int64))\n",
    "train_data = TensorDataset(Resize(32)(torch.tensor(set_C_ims.transpose(0,3,1,2)/255).float()), Resize(32)(torch.tensor(set_C_ims.transpose(0,3,1,2)/255).float()),\\\n",
    "                                     torch.tensor(set_C_labs).to(torch.int64))\n",
    "train_size = int(0.7 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "# test_size = len(train_data) - train_size - val_size\n",
    "\n",
    "train_data, val_data = random_split(train_data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(train_data,\n",
    "                                                batch_size=batch_size,\n",
    "                                              shuffle=True) \n",
    "val_data = torch.utils.data.DataLoader(val_data,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=False)\n",
    "# test_data = torch.utils.data.DataLoader(test_data,\n",
    "#                                                 batch_size=batch_size,\n",
    "#                                               shuffle=False)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1680, 720)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size, val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "Epoch 0, Loss: 0.6636428833007812, Accuracy: 37.916666666666664%\n",
      "Epoch 20, Loss: 0.00100385257974267, Accuracy: 27.55952380952381%\n",
      "Epoch 40, Loss: 6.923260662006214e-05, Accuracy: 27.738095238095237%\n",
      "Epoch 60, Loss: 4.833959974348545e-05, Accuracy: 27.738095238095237%\n",
      "Epoch 80, Loss: 3.9166287024272606e-05, Accuracy: 27.738095238095237%\n",
      "Epoch 100, Loss: 1.7539585314807482e-05, Accuracy: 27.738095238095237%\n",
      "Epoch 120, Loss: 1.245966359419981e-05, Accuracy: 27.738095238095237%\n",
      "Epoch 140, Loss: 2.1402658603619784e-05, Accuracy: 27.738095238095237%\n",
      "Epoch 160, Loss: 5.995202172925929e-06, Accuracy: 27.738095238095237%\n",
      "Epoch 180, Loss: 6.452137768064858e-06, Accuracy: 27.738095238095237%\n",
      "Pretrained Model: 0.278, Epoch 199, Loss: 2.7835872970172204e-05, Accuracy: 27.738095238095237%\n",
      "===================================================\n",
      "===================================================\n",
      "Epoch 0, Loss: 0.1951259970664978, Accuracy: 52.916666666666664%\n",
      "Epoch 20, Loss: 0.009456049650907516, Accuracy: 33.51190476190476%\n",
      "Epoch 40, Loss: 0.007158354856073856, Accuracy: 23.333333333333332%\n",
      "Epoch 60, Loss: 0.0019370377995073795, Accuracy: 24.404761904761905%\n",
      "Epoch 80, Loss: 2.4835264955669345e-09, Accuracy: 25.892857142857142%\n",
      "Epoch 100, Loss: 0.00041971958125941455, Accuracy: 27.738095238095237%\n",
      "Epoch 120, Loss: 3.311368734770781e-09, Accuracy: 26.428571428571427%\n",
      "Epoch 140, Loss: 0.0021961622405797243, Accuracy: 27.44047619047619%\n",
      "Epoch 160, Loss: 8.806278492556885e-05, Accuracy: 31.25%\n",
      "Epoch 180, Loss: 0.0, Accuracy: 30.833333333333332%\n",
      "Pretrained Model: 0.167, Epoch 199, Loss: 0.0, Accuracy: 30.833333333333332%\n",
      "===================================================\n",
      "===================================================\n",
      "Epoch 0, Loss: 0.026131656020879745, Accuracy: 72.97619047619048%\n",
      "Epoch 20, Loss: 0.012275105342268944, Accuracy: 61.726190476190474%\n",
      "Epoch 40, Loss: 0.0007124135736376047, Accuracy: 52.55952380952381%\n",
      "Epoch 60, Loss: 0.007894732058048248, Accuracy: 50.05952380952381%\n",
      "Epoch 80, Loss: 0.003051579697057605, Accuracy: 39.82142857142857%\n",
      "Epoch 100, Loss: 0.0054671564139425755, Accuracy: 32.55952380952381%\n",
      "Epoch 120, Loss: 0.00016844080528244376, Accuracy: 25.833333333333332%\n",
      "Epoch 140, Loss: 1.1811144759121817e-05, Accuracy: 24.226190476190474%\n",
      "Epoch 160, Loss: 0.00018487167835701257, Accuracy: 26.607142857142858%\n",
      "Epoch 180, Loss: 0.0004323518951423466, Accuracy: 27.738095238095237%\n",
      "Pretrained Model: 0.694, Epoch 199, Loss: 8.278417951146366e-09, Accuracy: 27.083333333333332%\n",
      "===================================================\n",
      "===================================================\n",
      "Epoch 0, Loss: 0.6041291952133179, Accuracy: 26.19047619047619%\n",
      "Epoch 20, Loss: 0.0006423339364118874, Accuracy: 24.88095238095238%\n",
      "Epoch 40, Loss: 6.493373803095892e-05, Accuracy: 25.05952380952381%\n",
      "Epoch 60, Loss: 2.0525365471257828e-05, Accuracy: 25.05952380952381%\n",
      "Epoch 80, Loss: 2.4435010345769115e-05, Accuracy: 25.05952380952381%\n",
      "Epoch 100, Loss: 9.91578144748928e-06, Accuracy: 25.05952380952381%\n",
      "Epoch 120, Loss: 1.2443072591850068e-05, Accuracy: 25.05952380952381%\n",
      "Epoch 140, Loss: 5.438802872959059e-06, Accuracy: 25.05952380952381%\n",
      "Epoch 160, Loss: 7.530798939114902e-06, Accuracy: 25.05952380952381%\n",
      "Epoch 180, Loss: 3.791482413362246e-06, Accuracy: 25.05952380952381%\n",
      "Pretrained Model: 0.083, Epoch 199, Loss: 3.2136726986209396e-06, Accuracy: 25.05952380952381%\n",
      "===================================================\n",
      "===================================================\n",
      "Epoch 0, Loss: 0.09844392538070679, Accuracy: 72.14285714285714%\n",
      "Epoch 20, Loss: 0.017619626596570015, Accuracy: 64.52380952380952%\n",
      "Epoch 40, Loss: 0.012715722434222698, Accuracy: 42.79761904761905%\n",
      "Epoch 60, Loss: 0.005597997922450304, Accuracy: 33.333333333333336%\n",
      "Epoch 80, Loss: 0.0062617347575724125, Accuracy: 30.595238095238095%\n",
      "Epoch 100, Loss: 0.005938241723924875, Accuracy: 31.547619047619047%\n",
      "Epoch 120, Loss: 0.005702518858015537, Accuracy: 28.273809523809526%\n",
      "Epoch 140, Loss: 0.0013903822982683778, Accuracy: 27.797619047619047%\n",
      "Epoch 160, Loss: 1.655684478407693e-09, Accuracy: 24.702380952380953%\n",
      "Epoch 180, Loss: 0.0007068144041113555, Accuracy: 26.547619047619047%\n",
      "Pretrained Model: 0.556, Epoch 199, Loss: 3.2864883792171895e-07, Accuracy: 25.952380952380953%\n",
      "===================================================\n",
      "===================================================\n",
      "Epoch 0, Loss: 0.44306814670562744, Accuracy: 41.904761904761905%\n",
      "Epoch 20, Loss: 6.905480404384434e-05, Accuracy: 33.095238095238095%\n",
      "Epoch 40, Loss: 0.00017630442744120955, Accuracy: 33.095238095238095%\n",
      "Epoch 60, Loss: 2.954287083412055e-05, Accuracy: 33.095238095238095%\n",
      "Epoch 80, Loss: 1.4526704944728408e-05, Accuracy: 33.095238095238095%\n",
      "Epoch 100, Loss: 9.7485572041478e-06, Accuracy: 33.095238095238095%\n",
      "Epoch 120, Loss: 1.4968717550800648e-05, Accuracy: 33.095238095238095%\n",
      "Epoch 140, Loss: 8.42485223984113e-06, Accuracy: 33.095238095238095%\n",
      "Epoch 160, Loss: 9.984251846617553e-06, Accuracy: 33.095238095238095%\n",
      "Epoch 180, Loss: 6.146668965811841e-06, Accuracy: 33.095238095238095%\n",
      "Pretrained Model: 0.222, Epoch 199, Loss: 2.9967789032525616e-06, Accuracy: 33.095238095238095%\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "# class MaxLogitsLoss(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MaxLogitsLoss, self).__init__()\n",
    "\n",
    "#     def forward(self, logits, targets):\n",
    "#         max_logits = torch.sum(logits * targets, dim=1)\n",
    "#         loss = -max_logits.mean()\n",
    "#         return loss\n",
    "latent_dims = 64\n",
    "\n",
    "# model_path = {38: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.389_sid_ce.pth\",\n",
    "#               44: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.444_sid_ce.pth\",\n",
    "#               50: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.5_sid_ce.pth\",\n",
    "#               55: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.556_sid_ce.pth\",\n",
    "#               66: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.667_sid_ce.pth\",\n",
    "#               72: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.722_sid_ce.pth\",\n",
    "#               77: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.778_sid_ce.pth\",\n",
    "#               83: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.833_sid_ce.pth\"}\n",
    "\n",
    "model_paths = {}\n",
    "for fname in os.listdir(os.path.join(save_dir,'sid_checkpoints', 'before_self_talk_all_set_A')):\n",
    "    if fname.endswith('.pth'):\n",
    "        model_paths[str(fname.split('_')[-3])] = fname\n",
    "model_paths\n",
    "\n",
    "for choose in model_paths.keys():\n",
    "    print('===================================================')\n",
    "    triplet_lab_model = TripletLabelModel(latent_dims, 4)\n",
    "    triplet_lab_model.load_state_dict(torch.load(os.path.join(save_dir,'sid_checkpoints', 'before_self_talk_all_set_A', model_paths[str(choose)])))\n",
    "    triplet_lab_model = triplet_lab_model.to(device)\n",
    "    # criterion = MaxLogitsLoss()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(triplet_lab_model.parameters(), lr=0.001)\n",
    "    num_epochs = 200\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for anchor_ims, contrast_ims, labels in train_data:\n",
    "            anchor_ims = anchor_ims.to(device)\n",
    "            contrast_ims = contrast_ims.to(device)\n",
    "            # labels = F.one_hot(labels, num_classes=4)\n",
    "            # import ipdb;ipdb.set_trace()\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            _, label_logits = triplet_lab_model(anchor_ims)\n",
    "            predicted_labels = torch.argmax(label_logits, dim=1)\n",
    "            # import ipdb; ipdb.set_trace()\n",
    "            loss = criterion(label_logits, predicted_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(label_logits.data, 1)\n",
    "            # _, labels_max = torch.max(labels.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "        if epoch%20==0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}, Accuracy: {accuracy}%\")\n",
    "        \n",
    "        # print(f\"Epoch {epoch}, Loss: {loss.item()}, Accuracy: {accuracy}%\")\n",
    "\n",
    "    print(f\"Pretrained Model: {choose}, Epoch {epoch}, Loss: {loss.item()}, Accuracy: {accuracy}%\")\n",
    "    save_path = os.path.join(save_dir,'sid_checkpoints', 'after_self_talk_all_set_A',  f'0_set_A_maxlogits_acc_{choose}.pth')\n",
    "    torch.save(triplet_lab_model.state_dict(), save_path)\n",
    "    print('===================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## before after self talk accuracies and saving latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "latent_dims = 64\n",
    "\n",
    "# model_path = {38: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.389_sid_ce.pth\",\n",
    "#               44: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.444_sid_ce.pth\",\n",
    "#               50: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.5_sid_ce.pth\",\n",
    "#               55: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.556_sid_ce.pth\",\n",
    "#               66: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.667_sid_ce.pth\",\n",
    "#               72: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.722_sid_ce.pth\",\n",
    "#               77: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.778_sid_ce.pth\",\n",
    "#               83: \"./results/sid_checkpoints/0_set_A_label_and_triplet_0.833_sid_ce.pth\",}\n",
    "\n",
    "# chooses = model_path.keys()\n",
    "# model_paths = {}\n",
    "model_fnames = []\n",
    "for fname in os.listdir(os.path.join(save_dir,'sid_checkpoints', 'before_self_talk_all_set_A')):\n",
    "    if fname.endswith('.pth'):\n",
    "        model_fnames.append(fname.split('_')[-3])\n",
    "df = pd.DataFrame(columns=['model_name', 'type' 'accuracy'])\n",
    "for choose in model_fnames:\n",
    "    for model_type in ['before_self_talk', 'after_self_talk']:\n",
    "        triplet_lab_model = TripletLabelModel(latent_dims, 4)\n",
    "        if model_type == 'before_self_talk':\n",
    "            triplet_lab_model.load_state_dict(torch.load(os.path.join(save_dir,'sid_checkpoints', 'before_self_talk_all_set_A', f'0_set_A_label_and_triplet_{choose}_sid_ce.pth')))\n",
    "        else:\n",
    "            triplet_lab_model.load_state_dict(torch.load(os.path.join(save_dir,'sid_checkpoints', 'after_self_talk_all_set_A', f'0_set_A_maxlogits_acc_{choose}.pth')))\n",
    "        triplet_lab_model = triplet_lab_model.to(device)\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        latent_temp = np.zeros((val_size, latent_dims))\n",
    "        labels_temp = []\n",
    "        for anchor_ims, contrast_ims, labels in val_data:\n",
    "            anchor_ims = anchor_ims.to(device)\n",
    "            contrast_ims = contrast_ims.to(device)\n",
    "            # labels = F.one_hot(labels, num_classes=4)\n",
    "            # import ipdb; ipdb.set_trace()\n",
    "            labels = labels.to(device)\n",
    "            labels_temp.extend(labels.cpu().detach())\n",
    "            # optimizer.zero_grad()\n",
    "            latents, label_logits = triplet_lab_model(anchor_ims)\n",
    "            latent_temp[total:total+labels.size(0)] = latents.cpu().detach().numpy()\n",
    "            # import ipdb; ipdb.set_trace()\n",
    "            predicted_labels = torch.argmax(label_logits, dim=1)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(label_logits.data, 1)\n",
    "            # _, labels_max = torch.max(labels.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "        # save latents and labels as a pandas dataframe csv\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        if model_type == 'before_self_talk':\n",
    "            pd.DataFrame(latent_temp, index=labels_temp).to_csv(os.path.join(save_dir,'latents_self_talk', 'before', f'{choose}.csv'))\n",
    "        else:\n",
    "            pd.DataFrame(latent_temp, index=labels_temp).to_csv(os.path.join(save_dir,'latents_self_talk', 'after', f'{choose}.csv'))\n",
    "        \n",
    "        df = pd.concat([df, pd.DataFrame([[choose, model_type, accuracy]], columns=['model_name', 'type', 'accuracy'])], ignore_index=True)\n",
    "\n",
    "        \n",
    "        # print(f\"Epoch {epoch}, Loss: {loss.item()}, Accuracy: {accuracy}%\")\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>typeaccuracy</th>\n",
       "      <th>type</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before_self_talk</td>\n",
       "      <td>44.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after_self_talk</td>\n",
       "      <td>26.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before_self_talk</td>\n",
       "      <td>56.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after_self_talk</td>\n",
       "      <td>32.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before_self_talk</td>\n",
       "      <td>74.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after_self_talk</td>\n",
       "      <td>28.194444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before_self_talk</td>\n",
       "      <td>30.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after_self_talk</td>\n",
       "      <td>25.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before_self_talk</td>\n",
       "      <td>72.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after_self_talk</td>\n",
       "      <td>25.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>before_self_talk</td>\n",
       "      <td>46.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after_self_talk</td>\n",
       "      <td>33.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name typeaccuracy              type   accuracy\n",
       "0       0.278          NaN  before_self_talk  44.444444\n",
       "1       0.278          NaN   after_self_talk  26.805556\n",
       "2       0.167          NaN  before_self_talk  56.944444\n",
       "3       0.167          NaN   after_self_talk  32.916667\n",
       "4       0.694          NaN  before_self_talk  74.444444\n",
       "5       0.694          NaN   after_self_talk  28.194444\n",
       "6       0.083          NaN  before_self_talk  30.972222\n",
       "7       0.083          NaN   after_self_talk  25.555556\n",
       "8       0.556          NaN  before_self_talk  72.777778\n",
       "9       0.556          NaN   after_self_talk  25.416667\n",
       "10      0.222          NaN  before_self_talk  46.805556\n",
       "11      0.222          NaN   after_self_talk  33.888889"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/mnt/dv/wid/projects3/Rogers-muri-human-ai/sid/tmp/envs/alignment2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "latent_separation_df = pd.DataFrame(columns=['model_name', 'type', 'accuracy'])\n",
    "\n",
    "# use latents to predict labels by training a logistic regression model\n",
    "# calculate accuracy of the model\n",
    "\n",
    "fnames = os.listdir(os.path.join(save_dir,'latents_self_talk', 'before'))\n",
    "\n",
    "for type in ['before', 'after']:\n",
    "    for fname in fnames:\n",
    "        # print(fname)\n",
    "        latent_df = pd.read_csv(os.path.join(save_dir,'latents_self_talk', type, fname), index_col=0)\n",
    "        latent_df = latent_df.sample(frac=1)\n",
    "        latent_df = latent_df.reset_index(drop=True)\n",
    "        labels = latent_df.index\n",
    "        latent_df = latent_df.to_numpy()\n",
    "        lm = linear_model.LogisticRegression()\n",
    "        lm.fit(latent_df, labels)\n",
    "        latent_separation_df = pd.concat([latent_separation_df, pd.DataFrame([[fname.split('.csv')[0], type, lm.score(latent_df, labels)]], columns=['model_name', 'type', 'accuracy'])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>after</th>\n",
       "      <th>before</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.083</th>\n",
       "      <td>0.881944</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.167</th>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.997222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.222</th>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.278</th>\n",
       "      <td>0.912500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.556</th>\n",
       "      <td>0.693056</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.694</th>\n",
       "      <td>0.598611</td>\n",
       "      <td>0.998611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type           after    before\n",
       "model_name                    \n",
       "0.083       0.881944  1.000000\n",
       "0.167       0.861111  0.997222\n",
       "0.222       0.983333  1.000000\n",
       "0.278       0.912500  1.000000\n",
       "0.556       0.693056  1.000000\n",
       "0.694       0.598611  0.998611"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_separation_df.pivot_table(index='model_name', columns='type', values='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "categoricality_df = pd.DataFrame(columns=['model_name', 'type', 'categoricality'])\n",
    "\n",
    "# use latents to predict labels by training a logistic regression model\n",
    "# calculate accuracy of the model\n",
    "\n",
    "fnames = os.listdir(os.path.join(save_dir,'latents_self_talk', 'before'))\n",
    "\n",
    "for type in ['before', 'after']:\n",
    "    for fname in fnames:\n",
    "        latent_df = pd.read_csv(os.path.join(save_dir,'latents_self_talk', type, fname), index_col=0)\n",
    "        latent_df.sort_index()\n",
    "        latent_df = latent_df.sample(frac=1)\n",
    "        latent_df = latent_df.reset_index(drop=True)\n",
    "        labels = latent_df.index\n",
    "        latent_df = latent_df.to_numpy()\n",
    "        dist = pdist(latent_df)\n",
    "        blocksize = 120\n",
    "        block_diag = np.zeros((720,720))\n",
    "        for l in range(4):\n",
    "            block_diag[l*blocksize:(l+1)*blocksize,l*blocksize:(l+1)*blocksize] = 1\n",
    "\n",
    "        ### mask distA with block_diag\n",
    "        within_dist = squareform(dist)*block_diag\n",
    "        between_dist = squareform(dist)*(1-block_diag)\n",
    "\n",
    "        categoricality = np.log(np.mean(between_dist)/np.mean(within_dist))\n",
    "        categoricality_df = pd.concat([categoricality_df, pd.DataFrame([[fname.split('.csv')[0], type, categoricality]], columns=['model_name', 'type', 'categoricality'])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f08e3441550>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categoricality_df.pivot_table(index='model_name', columns='type', values='categoricality')[['before', 'after']].plot(kind='bar', figsize=(10, 5), title='Categoricality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5ec221b8ce1ddc6eafacfbc77a75e3f09c9fea6e76ac8503f9810425480e77e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
