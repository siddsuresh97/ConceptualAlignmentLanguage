
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
  0%|                                                                                                                       | 0/3 [00:30<?, ?it/s]
Traceback (most recent call last):
  File "/Users/siddharthsuresh/Projects/Wisconsin/ConceptualAlignmentLanguage/scripts/main.py", line 61, in <module>
    main()
  File "/Users/siddharthsuresh/Projects/Wisconsin/ConceptualAlignmentLanguage/scripts/main.py", line 54, in main
    training.train(args.model_save_dir, args.num_models, args.epochs, args.num_classes, args.batch_size,
  File "/Users/siddharthsuresh/Projects/Wisconsin/ConceptualAlignmentLanguage/src/training.py", line 102, in train
    torch.save(model.state_dict(), os.path.join(save_dir,f'{data_set}_{train_mode}_{model}'))
  File "/Users/siddharthsuresh/miniforge3/envs/pytorch_env/lib/python3.9/site-packages/torch/serialization.py", line 377, in save
    with _open_file_like(f, 'wb') as opened_file:
  File "/Users/siddharthsuresh/miniforge3/envs/pytorch_env/lib/python3.9/site-packages/torch/serialization.py", line 231, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/Users/siddharthsuresh/miniforge3/envs/pytorch_env/lib/python3.9/site-packages/torch/serialization.py", line 212, in __init__
    super(_open_file, self).__init__(open(name, mode))
OSError: [Errno 63] File name too long: '/Users/siddharthsuresh/Projects/Wisconsin/ConceptualAlignmentLanguage/scripts/../results/base_0_ConvAutoencoder(\n  (encoder): Encoder(\n    (encoder_cnn): Sequential(\n      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (4): ReLU(inplace=True)\n      (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n      (6): ReLU(inplace=True)\n    )\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n    (encoder_labels_lin): Linear(in_features=4, out_features=2, bias=True)\n    (encoder_lin): Sequential(\n      (0): Linear(in_features=1570, out_features=128, bias=True)\n      (1): ReLU(inplace=True)\n      (2): Linear(in_features=128, out_features=10, bias=True)\n    )\n  )\n  (decoder): Decoder(\n    (decoder_lin): Sequential(\n      (0): Linear(in_features=10, out_features=128, bias=True)\n      (1): ReLU(inplace=True)\n      (2): Linear(in_features=128, out_features=1570, bias=True)\n      (3): ReLU(inplace=True)\n    )\n    (decoder_labels_lin): Linear(in_features=2, out_features=4, bias=True)\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n    (unflatten): Unflatten(dim=1, unflattened_size=(32, 7, 7))\n    (decoder_conv): Sequential(\n      (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n      (6): ConvTranspose2d(8, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(3, 3), output_padding=(1, 1))\n    )\n  )\n  (custom_loss): CustomLoss(\n    (cross_entropy): CrossEntropyLoss()\n  )\n)'